# ðŸ“„ PDF Chatbot ðŸ¤–

An AI-powered Streamlit application that lets you **chat with any PDF** and retain conversational context across turns. Leveraging LangChain, FAISS, and Groqâ€™s hosted LLM, this tool transforms static documents into interactive knowledge assistants.

---

## âœ¨ Overview

PDF Chatbot ingests a PDF file, indexes its contents into a vector store, and answers user queries by combining:

1. ðŸ” **Retrieval**  
   FAISS-powered semantic search over PDF embeddings  
2. ðŸ§  **Generation**  
   Groqâ€™s `ChatGroq` LLM for fluent, on-point responses  
3. ðŸ’¬ **Memory**  
   Session-state storage of prior messages to handle follow-ups naturally  

The result is a responsive Q&A interface that â€œremembersâ€ what youâ€™ve already asked and refers back to the document when needed.

---

## ðŸš€ Features

- **Document Understanding**  
  - Splits PDF pages into chunks, embeds them via a pretrained HuggingFace model, and indexes with FAISS for lightning-fast lookups.

- **Conversational Memory**  
  - Stores each user and bot turn in session state so follow-up questions (â€œWhat about the previous section?â€) stay in context.

- **Seamless LLM Integration**  
  - Sends both retrieved document snippets and chat history to Groqâ€™s hosted model (`ChatGroq`)â€”no GPU setup or local model downloads.

- **On-Demand PDF Indexing**  
  - Upload any PDF in the sidebar; once indexed, you can immediately begin querying its content.

- **Single-File Deployment**  
  - All logic lives in `app.py`; configuration via `.env` (for local) or Streamlit secrets (for production).

---

## ðŸ—ï¸ Architecture

```mermaid
flowchart LR
  subgraph User Interface
    A[Streamlit UI] -->|upload| B[PDF Uploader]
    A -->|ask| E[Input Form]
    E --> F[Chat History Display]
  end

  B --> C[Temp PDF File] --> D[PDF Loader & Splitter] --> G[FAISS Index]
  E --> H{Chain?}
  H -->|PDF indexed| I[ConversationalRetrievalChain]
  H -->|No PDF| J[LLM-only Fallback]
  I --> K[ChatGroq] --> F
  J --> K --> F

  subgraph Storage
    G
    L[Session State: messages]
  end
```

## ðŸ“‚ Folder Structure
qna-chatbot/<br>
â”œâ”€â”€ app.py                   # Streamlit app entrypoint<br>
â”œâ”€â”€ requirements.txt         # Python dependencies<br>
â”œâ”€â”€ .gitignore               # Ignores .env, cache files<br>
â”œâ”€â”€ .env                     # Local-only secrets (git-ignored)<br>
â””â”€â”€ .streamlit/<br>
    *  â””â”€â”€ secrets.toml         # Placeholder for production secrets<br>

## ðŸŽ¯ Usage
1. Upload a PDF via the left sidebar.
2. Ask any question about its contents in the chat box and hit Send.
3. Follow up with additional queriesâ€”your previous messages and the document context are woven into each answer.

## ðŸ”’ Security & Secrets
**Local: store GROQ_API_KEY and GROQ_MODEL in a .env file (ignored by Git).**
**Production: configure the same keys in Streamlit Cloudâ€™s Settings â†’ Secrets (or commit a secrets.toml with placeholder values).**
